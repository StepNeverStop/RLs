ExperienceReplay: &ExperienceReplay {}

PrioritizedExperienceReplay: &PrioritizedExperienceReplay
  alpha: 0.6 # priority
  beta: 0.4 # importance sampling ratio
  epsilon: 0.01
  global_v: false

NStepExperienceReplay: &NStepExperienceReplay
  n_step: 4

NStepPrioritizedExperienceReplay: &NStepPrioritizedExperienceReplay
  alpha: 0.6
  beta: 0.4
  epsilon: 0.01
  global_v: false
  n_step: 4

# off-policy with rnn
EpisodeExperienceReplay: &EpisodeExperienceReplay
  burn_in_time_step: 20
  train_time_step: 40 # ~

# Multi-Agents

MultiAgentCentralExperienceReplay: {} # TODO

MultiAgentExperienceReplay:
  ExperienceReplay:
    <<: *ExperienceReplay

  PrioritizedExperienceReplay:
    <<: *PrioritizedExperienceReplay

  NStepExperienceReplay:
    <<: *NStepExperienceReplay

  NStepPrioritizedExperienceReplay:
    <<: *NStepPrioritizedExperienceReplay

  EpisodeExperienceReplay:
    <<: *EpisodeExperienceReplay
